{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CC2Vec and DeepJIT data and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2vec_test = pickle.load(open('/home/aiotlab3/RISE/Manh/data/gerrit/cc2vec/gerrit_test.pkl', 'rb'))\n",
    "deepjit_test = pickle.load(open('/home/aiotlab3/RISE/Manh/data/gerrit/cc2vec/gerrit_test_dextend_raw.pkl', 'rb'))\n",
    "dictionary = pickle.load(open('/home/aiotlab3/RISE/Manh/data/gerrit/cc2vec/gerrit_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'added_code': [\"suite ( 'gr - plugin - host tests' , ( ) = > {\",\n",
       "   \"html resource paths : [ 'plugins / foo / bar' , 'plugins / baz' ] ,\",\n",
       "   \"js resource paths : [ 'plugins / 42' ] ,\"],\n",
       "  'removed_code': [\"suite ( 'gr - diff tests' , ( ) = > {\",\n",
       "   \"html resource paths : [ 'foo / bar' , 'baz' ] ,\",\n",
       "   \"js resource paths : [ '42' ] ,\"]},\n",
       " {'added_code': [\"test ( 'multiple ui plugins per java plugin' , ( ) = > {\",\n",
       "   \"const file1 = 'http : / / test . com / plugins / qaz / static / foo . nocache . js' ;\",\n",
       "   \"const file2 = 'http : / / test . com / plugins / qaz / static / bar . js' ;\",\n",
       "   'Gerrit . setPluginsPending ( [ file1 , file2 ] ) ;',\n",
       "   \"Gerrit . install ( ( ) = > { } , '0 . 1' , file1 ) ;\",\n",
       "   \"Gerrit . install ( ( ) = > { } , '0 . 1' , file2 ) ;\",\n",
       "   'return Gerrit . awaitPluginsLoaded ( ) ;',\n",
       "   '} ) ;',\n",
       "   ''],\n",
       "  'removed_code': []},\n",
       " {'added_code': ['Gerrit . setPluginsCount ( Object . keys ( pluginsPending ) . length ) ;'],\n",
       "  'removed_code': ['Gerrit . setPluginsCount ( plugins . length ) ;']}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids, labels, messages, commits = cc2vec_test\n",
    "commits[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"suite ( 'gr - diff tests' , ( ) = > {\",\n",
       " \"suite ( 'gr - plugin - host tests' , ( ) = > {\",\n",
       " \"html resource paths : [ 'foo / bar' , 'baz' ] ,\",\n",
       " \"html resource paths : [ 'plugins / foo / bar' , 'plugins / baz' ] ,\",\n",
       " \"js resource paths : [ '42' ] ,\",\n",
       " \"js resource paths : [ 'plugins / 42' ] ,\",\n",
       " \"test ( 'multiple ui plugins per java plugin' , ( ) = > {\",\n",
       " \"const file1 = 'http : / / test . com / plugins / qaz / static / foo . nocache . js' ;\",\n",
       " \"const file2 = 'http : / / test . com / plugins / qaz / static / bar . js' ;\",\n",
       " 'Gerrit . setPluginsPending ( [ file1 , file2 ] ) ;']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids, labels, messages, commits = deepjit_test\n",
    "commits[4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train/test-set and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'moment'\n",
    "\n",
    "train = pickle.load(open(f'data/{project_name}/clean/{project_name}_train.pkl', 'rb'))\n",
    "deepjit_train = pickle.load(open(f'data/{project_name}/clean/{project_name}_train_dextend.pkl', 'rb'))\n",
    "test = pickle.load(open(f'data/{project_name}/clean/{project_name}_test.pkl', 'rb'))\n",
    "dictionary = pickle.load(open(f\"data/{project_name}/clean/{project_name}_dict.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, train_messages, train_commits, train_labels = train\n",
    "deepjit_train_ids, deepjit_train_messages, deepjit_train_commits, deepjit_train_labels = deepjit_train\n",
    "test_ids, test_messages, test_commits, test_labels = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'added_code': [\"m : [ 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82' , 'Ñ\\x98ÐµÐ´Ð½Ð¾Ð³ Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ð°' ] , mm : [ 'Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82' , 'Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ð°' , 'Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ð°' ] , d : [ 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð´Ð°Ð½' , 'Ñ\\x98ÐµÐ´Ð½Ð¾Ð³ Ð´Ð°Ð½Ð°' ] , M : [ 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼ÐµÑ\\x81ÐµÑ\\x86' , 'Ñ\\x98ÐµÐ´Ð½Ð¾Ð³ Ð¼ÐµÑ\\x81ÐµÑ\\x86Ð°' ] , y : [ 'Ñ\\x98ÐµÐ´Ð½Ñ\\x83 Ð³Ð¾Ð´Ð¸Ð½Ñ\\x83' , 'Ñ\\x98ÐµÐ´Ð½Ðµ Ð³Ð¾Ð´Ð¸Ð½Ðµ' ] , yy : [ 'Ð³Ð¾Ð´Ð¸Ð½Ñ\\x83' , 'Ð³Ð¾Ð´Ð¸Ð½Ðµ' , 'Ð³Ð¾Ð´Ð¸Ð½Ð°' ] , if ( number % 10 > = 1 & & number % 10 < = 4 & & ( number % 100 < 10 | | number % 100 > = 20 ) ) { return number % 10 = = = 1 ? wordKey [ 0 ] : wordKey [ 1 ] } return wordKey [ 2 ] translate : function ( number , withoutSuffix , key , isFuture ) { / / Nominativ if ( key = = = 'y' & & withoutSuffix ) return 'Ñ\\x98ÐµÐ´Ð½Ð° Ð³Ð¾Ð´Ð¸Ð½Ð°' return isFuture | | withoutSuffix ? wordKey [ 0 ] : wordKey [ 1 ] ; const word = translator . correctGrammaticalCase ( number , wordKey ) / / Nominativ if ( key = = = 'yy' & & withoutSuffix & & word = = = 'Ð³Ð¾Ð´Ð¸Ð½Ñ\\x83' ) { return ( number + ' Ð³Ð¾Ð´Ð¸Ð½Ð°' ) } return ( number + ' ' + word ) ;\",\n",
       "   'd : translator . translate , M : translator . translate , y : translator . translate ,'],\n",
       "  'removed_code': [\"m : [ 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82' , 'Ñ\\x98ÐµÐ´Ð½Ðµ Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ðµ' ] , mm : [ 'Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82' , 'Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ðµ' , 'Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ð°' ] , yy : [ 'Ð³Ð¾Ð´Ð¸Ð½Ð°' , 'Ð³Ð¾Ð´Ð¸Ð½Ðµ' , 'Ð³Ð¾Ð´Ð¸Ð½Ð°' ] , return number = = = 1 ? wordKey [ 0 ] : number > = 2 & & number < = 4 ? wordKey [ 1 ] : wordKey [ 2 ] ; translate : function ( number , withoutSuffix , key ) { return withoutSuffix ? wordKey [ 0 ] : wordKey [ 1 ] ; } else { return ( number + ' ' + translator . correctGrammaticalCase ( number , wordKey ) ) ;\",\n",
       "   \"d : 'Ð´Ð°Ð½' , M : 'Ð¼ÐµÑ\\x81ÐµÑ\\x86' , y : 'Ð³Ð¾Ð´Ð¸Ð½Ñ\\x83' ,\"]},\n",
       " {'added_code': [\"import { without } from 'lodash' ;\",\n",
       "   \"m : [ 'jedan minut' , 'jednog minuta' ] , mm : [ 'minut' , 'minuta' , 'minuta' ] , d : [ 'jedan dan' , 'jednog dana' ] , M : [ 'jedan mesec' , 'jednog meseca' ] , y : [ 'jednu godinu' , 'jedne godine' ] , yy : [ 'godinu' , 'godine' , 'godina' ] , if ( number % 10 > = 1 & & number % 10 < = 4 & & ( number % 100 < 10 | | number % 100 > = 20 ) ) { return number % 10 = = = 1 ? wordKey [ 0 ] : wordKey [ 1 ] } return wordKey [ 2 ] translate : function ( number , withoutSuffix , key , isFuture ) { / / Nominativ if ( key = = = 'y' & & withoutSuffix ) return 'jedna godina' return isFuture | | withoutSuffix ? wordKey [ 0 ] : wordKey [ 1 ] ; const word = translator . correctGrammaticalCase ( number , wordKey ) / / Nominativ if ( key = = = 'yy' & & withoutSuffix & & word = = = 'godinu' ) { return ( number + ' godina' ) } return ( number + ' ' + word ) ;\",\n",
       "   'd : translator . translate , M : translator . translate , y : translator . translate ,'],\n",
       "  'removed_code': ['',\n",
       "   \"m : [ 'jedan minut' , 'jedne minute' ] , mm : [ 'minut' , 'minute' , 'minuta' ] , yy : [ 'godina' , 'godine' , 'godina' ] , return number = = = 1 ? wordKey [ 0 ] : number > = 2 & & number < = 4 ? wordKey [ 1 ] : wordKey [ 2 ] ; translate : function ( number , withoutSuffix , key ) { return withoutSuffix ? wordKey [ 0 ] : wordKey [ 1 ] ; } else { return ( number + ' ' + translator . correctGrammaticalCase ( number , wordKey ) ) ;\",\n",
       "   \"d : 'dan' , M : 'mesec' , y : 'godinu' ,\"]},\n",
       " {'added_code': [\"'2 Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ð°' ,\",\n",
       "   \"'21 Ñ\\x81Ð°Ñ\\x82' , 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð´Ð°Ð½' , 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð´Ð°Ð½' ,\",\n",
       "   \"'Ñ\\x98ÐµÐ´Ð°Ð½ Ð´Ð°Ð½' ,\",\n",
       "   \"'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼ÐµÑ\\x81ÐµÑ\\x86' , 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼ÐµÑ\\x81ÐµÑ\\x86' , 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼ÐµÑ\\x81ÐµÑ\\x86' ,\",\n",
       "   \"'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼ÐµÑ\\x81ÐµÑ\\x86' ,\",\n",
       "   \"'Ñ\\x98ÐµÐ´Ð½Ð° Ð³Ð¾Ð´Ð¸Ð½Ð°' ,\",\n",
       "   \"'Ñ\\x98ÐµÐ´Ð½Ð° Ð³Ð¾Ð´Ð¸Ð½Ð°' ,\"],\n",
       "  'removed_code': [\"'2 Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ðµ' ,\",\n",
       "   \"'21 Ñ\\x81Ð°Ñ\\x82Ð¸' , 'Ð´Ð°Ð½' , 'Ð´Ð°Ð½' ,\",\n",
       "   \"'Ð´Ð°Ð½' ,\",\n",
       "   \"'Ð¼ÐµÑ\\x81ÐµÑ\\x86' , 'Ð¼ÐµÑ\\x81ÐµÑ\\x86' , 'Ð¼ÐµÑ\\x81ÐµÑ\\x86' ,\",\n",
       "   \"'Ð¼ÐµÑ\\x81ÐµÑ\\x86' ,\",\n",
       "   \"'Ð³Ð¾Ð´Ð¸Ð½Ñ\\x83' ,\",\n",
       "   \"'Ð³Ð¾Ð´Ð¸Ð½Ñ\\x83' ,\"]},\n",
       " {'added_code': [\"'2 minuta' ,\",\n",
       "   \"'21 sat' , 'jedan dan' , 'jedan dan' ,\",\n",
       "   \"'jedan dan' ,\",\n",
       "   \"'jedan mesec' , 'jedan mesec' , 'jedan mesec' ,\",\n",
       "   \"'jedan mesec' ,\",\n",
       "   \"'jedna godina' ,\",\n",
       "   \"'jedna godina' ,\"],\n",
       "  'removed_code': [\"'2 minute' ,\",\n",
       "   \"'21 sati' , 'dan' , 'dan' ,\",\n",
       "   \"'dan' ,\",\n",
       "   \"'mesec' , 'mesec' , 'mesec' ,\",\n",
       "   \"'mesec' ,\",\n",
       "   \"'godinu' ,\",\n",
       "   \"'godinu' ,\"]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_commits[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"m : [ 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82' , 'Ñ\\x98ÐµÐ´Ð½Ð¾Ð³ Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ð°' ] , mm : [ 'Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82' , 'Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ð°' , 'Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ð°' ] , d : [ 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð´Ð°Ð½' , 'Ñ\\x98ÐµÐ´Ð½Ð¾Ð³ Ð´Ð°Ð½Ð°' ] , M : [ 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼ÐµÑ\\x81ÐµÑ\\x86' , 'Ñ\\x98ÐµÐ´Ð½Ð¾Ð³ Ð¼ÐµÑ\\x81ÐµÑ\\x86Ð°' ] , y : [ 'Ñ\\x98ÐµÐ´Ð½Ñ\\x83 Ð³Ð¾Ð´Ð¸Ð½Ñ\\x83' , 'Ñ\\x98ÐµÐ´Ð½Ðµ Ð³Ð¾Ð´Ð¸Ð½Ðµ' ] , yy : [ 'Ð³Ð¾Ð´Ð¸Ð½Ñ\\x83' , 'Ð³Ð¾Ð´Ð¸Ð½Ðµ' , 'Ð³Ð¾Ð´Ð¸Ð½Ð°' ] , if ( number % 10 > = 1 & & number % 10 < = 4 & & ( number % 100 < 10 | | number % 100 > = 20 ) ) { return number % 10 = = = 1 ? wordKey [ 0 ] : wordKey [ 1 ] } return wordKey [ 2 ] translate : function ( number , withoutSuffix , key , isFuture ) { / / Nominativ if ( key = = = 'y' & & withoutSuffix ) return 'Ñ\\x98ÐµÐ´Ð½Ð° Ð³Ð¾Ð´Ð¸Ð½Ð°' return isFuture | | withoutSuffix ? wordKey [ 0 ] : wordKey [ 1 ] ; const word = translator . correctGrammaticalCase ( number , wordKey ) / / Nominativ if ( key = = = 'yy' & & withoutSuffix & & word = = = 'Ð³Ð¾Ð´Ð¸Ð½Ñ\\x83' ) { return ( number + ' Ð³Ð¾Ð´Ð¸Ð½Ð°' ) } return ( number + ' ' + word ) ;\",\n",
       " \"m : [ 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82' , 'Ñ\\x98ÐµÐ´Ð½Ðµ Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ðµ' ] , mm : [ 'Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82' , 'Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ðµ' , 'Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ð°' ] , yy : [ 'Ð³Ð¾Ð´Ð¸Ð½Ð°' , 'Ð³Ð¾Ð´Ð¸Ð½Ðµ' , 'Ð³Ð¾Ð´Ð¸Ð½Ð°' ] , return number = = = 1 ? wordKey [ 0 ] : number > = 2 & & number < = 4 ? wordKey [ 1 ] : wordKey [ 2 ] ; translate : function ( number , withoutSuffix , key ) { return withoutSuffix ? wordKey [ 0 ] : wordKey [ 1 ] ; } else { return ( number + ' ' + translator . correctGrammaticalCase ( number , wordKey ) ) ;\",\n",
       " 'd : translator . translate , M : translator . translate , y : translator . translate ,',\n",
       " \"d : 'Ð´Ð°Ð½' , M : 'Ð¼ÐµÑ\\x81ÐµÑ\\x86' , y : 'Ð³Ð¾Ð´Ð¸Ð½Ñ\\x83' ,\",\n",
       " \"import { without } from 'lodash' ;\",\n",
       " '',\n",
       " \"m : [ 'jedan minut' , 'jednog minuta' ] , mm : [ 'minut' , 'minuta' , 'minuta' ] , d : [ 'jedan dan' , 'jednog dana' ] , M : [ 'jedan mesec' , 'jednog meseca' ] , y : [ 'jednu godinu' , 'jedne godine' ] , yy : [ 'godinu' , 'godine' , 'godina' ] , if ( number % 10 > = 1 & & number % 10 < = 4 & & ( number % 100 < 10 | | number % 100 > = 20 ) ) { return number % 10 = = = 1 ? wordKey [ 0 ] : wordKey [ 1 ] } return wordKey [ 2 ] translate : function ( number , withoutSuffix , key , isFuture ) { / / Nominativ if ( key = = = 'y' & & withoutSuffix ) return 'jedna godina' return isFuture | | withoutSuffix ? wordKey [ 0 ] : wordKey [ 1 ] ; const word = translator . correctGrammaticalCase ( number , wordKey ) / / Nominativ if ( key = = = 'yy' & & withoutSuffix & & word = = = 'godinu' ) { return ( number + ' godina' ) } return ( number + ' ' + word ) ;\",\n",
       " \"m : [ 'jedan minut' , 'jedne minute' ] , mm : [ 'minut' , 'minute' , 'minuta' ] , yy : [ 'godina' , 'godine' , 'godina' ] , return number = = = 1 ? wordKey [ 0 ] : number > = 2 & & number < = 4 ? wordKey [ 1 ] : wordKey [ 2 ] ; translate : function ( number , withoutSuffix , key ) { return withoutSuffix ? wordKey [ 0 ] : wordKey [ 1 ] ; } else { return ( number + ' ' + translator . correctGrammaticalCase ( number , wordKey ) ) ;\",\n",
       " 'd : translator . translate , M : translator . translate , y : translator . translate ,',\n",
       " \"d : 'dan' , M : 'mesec' , y : 'godinu' ,\",\n",
       " \"'2 Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ð°' ,\",\n",
       " \"'2 Ð¼Ð¸Ð½Ñ\\x83Ñ\\x82Ðµ' ,\",\n",
       " \"'21 Ñ\\x81Ð°Ñ\\x82' , 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð´Ð°Ð½' , 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð´Ð°Ð½' ,\",\n",
       " \"'21 Ñ\\x81Ð°Ñ\\x82Ð¸' , 'Ð´Ð°Ð½' , 'Ð´Ð°Ð½' ,\",\n",
       " \"'Ñ\\x98ÐµÐ´Ð°Ð½ Ð´Ð°Ð½' ,\",\n",
       " \"'Ð´Ð°Ð½' ,\",\n",
       " \"'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼ÐµÑ\\x81ÐµÑ\\x86' , 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼ÐµÑ\\x81ÐµÑ\\x86' , 'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼ÐµÑ\\x81ÐµÑ\\x86' ,\",\n",
       " \"'Ð¼ÐµÑ\\x81ÐµÑ\\x86' , 'Ð¼ÐµÑ\\x81ÐµÑ\\x86' , 'Ð¼ÐµÑ\\x81ÐµÑ\\x86' ,\",\n",
       " \"'Ñ\\x98ÐµÐ´Ð°Ð½ Ð¼ÐµÑ\\x81ÐµÑ\\x86' ,\",\n",
       " \"'Ð¼ÐµÑ\\x81ÐµÑ\\x86' ,\",\n",
       " \"'Ñ\\x98ÐµÐ´Ð½Ð° Ð³Ð¾Ð´Ð¸Ð½Ð°' ,\",\n",
       " \"'Ð³Ð¾Ð´Ð¸Ð½Ñ\\x83' ,\",\n",
       " \"'Ñ\\x98ÐµÐ´Ð½Ð° Ð³Ð¾Ð´Ð¸Ð½Ð°' ,\",\n",
       " \"'Ð³Ð¾Ð´Ð¸Ð½Ñ\\x83' ,\",\n",
       " \"'2 minuta' ,\",\n",
       " \"'2 minute' ,\",\n",
       " \"'21 sat' , 'jedan dan' , 'jedan dan' ,\",\n",
       " \"'21 sati' , 'dan' , 'dan' ,\",\n",
       " \"'jedan dan' ,\",\n",
       " \"'dan' ,\",\n",
       " \"'jedan mesec' , 'jedan mesec' , 'jedan mesec' ,\",\n",
       " \"'mesec' , 'mesec' , 'mesec' ,\",\n",
       " \"'jedan mesec' ,\",\n",
       " \"'mesec' ,\",\n",
       " \"'jedna godina' ,\",\n",
       " \"'godinu' ,\",\n",
       " \"'jedna godina' ,\",\n",
       " \"'godinu' ,\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepjit_train_commits[6]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_commit_code_line(data, max_line, max_length):\n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        if len(d) == max_line:\n",
    "            new_data.append(d)\n",
    "        elif len(d) > max_line:\n",
    "            new_data.append(d[:max_line])\n",
    "        else:\n",
    "            num_added_line = max_line - len(d)\n",
    "            for _ in range(num_added_line):\n",
    "                d.append(('<NULL> ' * max_length).strip())\n",
    "            new_data.append(d)\n",
    "    return new_data\n",
    "\n",
    "def padding_multiple_length(lines, max_length):\n",
    "    return [padding_length(line=l, max_length=max_length) for l in lines]\n",
    "\n",
    "def padding_length(line, max_length):\n",
    "    line_length = len(line.split())\n",
    "    if line_length < max_length:\n",
    "        return str(line + ' <NULL>' * (max_length - line_length)).strip()\n",
    "    elif line_length > max_length:\n",
    "        line_split = line.split()\n",
    "        return ' '.join([line_split[i] for i in range(max_length)])\n",
    "    else:\n",
    "        return line\n",
    "\n",
    "def padding_data(data, dictionary, params, type):\n",
    "    if type == 'msg':\n",
    "        pad_msg = padding_message(data=data, max_length=params[\"message_length\"])\n",
    "        pad_msg = mapping_dict_msg(pad_msg=pad_msg, dict_msg=dictionary)\n",
    "        return pad_msg\n",
    "    elif type == 'code':\n",
    "        pad_code = padding_commit_code(data=data, max_line=params[\"code_line\"], max_length=params[\"deepjit_code_length\"])\n",
    "        pad_code = mapping_dict_code(pad_code=pad_code, dict_code=dictionary)\n",
    "        return pad_code\n",
    "    else:\n",
    "        print('Your type is incorrect -- please correct it')\n",
    "        exit()\n",
    "\n",
    "def padding_message(data, max_length):\n",
    "    return [padding_length(line=d, max_length=max_length) for d in data]\n",
    "\n",
    "def mapping_dict_msg(pad_msg, dict_msg):\n",
    "    return np.array(\n",
    "        [np.array([dict_msg[w.lower()] if w.lower() in dict_msg.keys() else dict_msg['<NULL>'] for w in line.split(' ')]) for line in pad_msg])\n",
    "\n",
    "\n",
    "def mapping_dict_code(pad_code, dict_code):\n",
    "    new_pad = [\n",
    "        np.array([np.array([dict_code[w.lower()] if w.lower() in dict_code else dict_code['<NULL>'] for w in l.split()]) for l in ml])\n",
    "        for ml in pad_code]\n",
    "    return np.array(new_pad)\n",
    "\n",
    "def padding_commit_code(data, max_line, max_length):\n",
    "    padding_length = padding_commit_code_length(data=data, max_length=max_length)\n",
    "    return padding_commit_code_line(\n",
    "        padding_length, max_line=max_line, max_length=max_length\n",
    "    )\n",
    "\n",
    "def padding_commit_code_length(data, max_length):\n",
    "    return [padding_multiple_length(lines=commit, max_length=max_length) for commit in data]\n",
    "\n",
    "def cc2vec_padding_commit_file(data, max_file, max_line, max_length):\n",
    "    new_commits = []\n",
    "    for commit in data:\n",
    "        new_commit = []\n",
    "        if len(commit) == max_file:\n",
    "            new_commit = commit\n",
    "        elif len(commit) > max_file:\n",
    "            new_commit = commit[:max_file]\n",
    "        else:\n",
    "            num_added_file = max_file - len(commit)\n",
    "            new_files = []\n",
    "            for _ in range(num_added_file):\n",
    "                file = [('<NULL> ' * max_length).strip() for _ in range(max_line)]\n",
    "                new_files.append(file)\n",
    "            new_commit = commit + new_files\n",
    "        new_commits.append(new_commit)\n",
    "    return new_commits\n",
    "\n",
    "def cc2vec_padding_commit_code_line(data, max_line, max_length):\n",
    "    new_commits = []\n",
    "    for commit in data:\n",
    "        new_files = []\n",
    "        for file in commit:\n",
    "            new_file = file\n",
    "            if len(file) == max_line:\n",
    "                new_file = file\n",
    "            elif len(file) > max_line:\n",
    "                new_file = file[:max_line]\n",
    "            else:\n",
    "                num_added_line = max_line - len(file)\n",
    "                new_file = file\n",
    "                for _ in range(num_added_line):\n",
    "                    new_file.append(('<NULL> ' * max_length).strip())\n",
    "            new_files.append(new_file)\n",
    "        new_commits.append(new_files)\n",
    "    return new_commits\n",
    "\n",
    "def cc2vec_padding_commit_code_length(data, max_length):\n",
    "    commits = []\n",
    "    for commit in data:\n",
    "        new_commit = []\n",
    "        for file in commit:\n",
    "            new_file = []\n",
    "            for line in file:\n",
    "                new_line = cc2vec_padding_length(line, max_length=max_length)\n",
    "                new_file.append(new_line)\n",
    "            new_commit.append(new_file)\n",
    "        commits.append(new_commit)\n",
    "    return commits\n",
    "\n",
    "def cc2vec_padding_length(line, max_length):\n",
    "    line_length = len(line.split())\n",
    "    if line_length < max_length:\n",
    "        return str(line + ' <NULL>' * (max_length - line_length)).strip()\n",
    "    elif line_length > max_length:\n",
    "        line_split = line.split()\n",
    "        return ' '.join([line_split[i] for i in range(max_length)])\n",
    "    else:\n",
    "        return line\n",
    "\n",
    "def cc2vec_convert_msg_to_label(pad_msg, dict_msg):\n",
    "    nrows, ncols = pad_msg.shape\n",
    "    labels = []\n",
    "    for i in range(nrows):\n",
    "        column = list(set(list(pad_msg[i, :])))\n",
    "        label = np.zeros(len(dict_msg))\n",
    "        for c in column:\n",
    "            label[c] = 1\n",
    "        labels.append(label)\n",
    "    return np.array(labels)\n",
    "\n",
    "def cc2vec_mapping_dict_msg(pad_msg, dict_msg):\n",
    "    return np.array(\n",
    "        [np.array([dict_msg[w.lower()] if w.lower() in dict_msg.keys() else dict_msg['<NULL>'] for w in line.split(' ')]) for line in pad_msg])\n",
    "\n",
    "def cc2vec_mapping_dict_code(pad_code, dict_code):\n",
    "    new_pad_code = []\n",
    "    for commit in pad_code:\n",
    "        new_files = []\n",
    "        for file in commit:\n",
    "            new_file = []\n",
    "            for line in file:\n",
    "                new_line = []\n",
    "                for token in line.split(' '):\n",
    "                    if token.lower() in dict_code.keys():\n",
    "                        new_line.append(dict_code[token.lower()])\n",
    "                    else:\n",
    "                        new_line.append(dict_code['<NULL>'])\n",
    "                new_file.append(np.array(new_line))\n",
    "            new_file = np.array(new_file)\n",
    "            new_files.append(new_file)\n",
    "        new_files = np.array(new_files)\n",
    "        new_pad_code.append(new_files)\n",
    "    return np.array(new_pad_code)\n",
    "\n",
    "def cc2vec_padding_commit_code(data, max_file, max_line, max_length):\n",
    "    padding_length = cc2vec_padding_commit_code_length(data=data, max_length=max_length)\n",
    "    padding_line = cc2vec_padding_commit_code_line(padding_length, max_line=max_line, max_length=max_length)\n",
    "    return cc2vec_padding_commit_file(\n",
    "        data=padding_line,\n",
    "        max_file=max_file,\n",
    "        max_line=max_line,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "def cc2vec_clean_and_reformat_code(data):\n",
    "    # remove empty lines in code; divide code to two part: added_code and removed_code\n",
    "    print(data)\n",
    "    new_diff_added_code, new_diff_removed_code = [], []\n",
    "    for diff in data:\n",
    "        files = []\n",
    "        print(diff)\n",
    "        for file in diff['code_changes']:\n",
    "            lines = file['added_code']\n",
    "            new_lines = [line for line in lines if len(line.strip()) > 0]\n",
    "            files.append(new_lines)\n",
    "        new_diff_added_code.append(files)\n",
    "    for diff in data:\n",
    "        files = []\n",
    "        for file in diff['code_changes']:\n",
    "            lines = file['removed_code']\n",
    "            new_lines = [line for line in lines if len(line.strip()) > 0]\n",
    "            files.append(new_lines)\n",
    "        new_diff_removed_code.append(files)\n",
    "    return (new_diff_added_code, new_diff_removed_code)\n",
    "\n",
    "def cc2vec_padding_message(data, max_length):\n",
    "    return [cc2vec_padding_length(line=d, max_length=max_length) for d in data]\n",
    "\n",
    "def hunks_to_code(file_levels: list) -> str:\n",
    "    code = []\n",
    "    for file_level in file_levels:\n",
    "        for hunk in file_level['code_changes']:\n",
    "            code.append(hunk['added_code'])\n",
    "            code.append(hunk['removed_code'])\n",
    "\n",
    "    return code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data for DeepJIT and CC2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/aiotlab3/RISE/Manh/TanDatasets/cc2vec-preprocessing-data.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baiotlab3/home/aiotlab3/RISE/Manh/TanDatasets/cc2vec-preprocessing-data.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# DeepJIT\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baiotlab3/home/aiotlab3/RISE/Manh/TanDatasets/cc2vec-preprocessing-data.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m code \u001b[39m=\u001b[39m hunks_to_code(train_commits)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baiotlab3/home/aiotlab3/RISE/Manh/TanDatasets/cc2vec-preprocessing-data.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m dict_msg, dict_code \u001b[39m=\u001b[39m dictionary\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baiotlab3/home/aiotlab3/RISE/Manh/TanDatasets/cc2vec-preprocessing-data.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m pad_msg \u001b[39m=\u001b[39m padding_data(data\u001b[39m=\u001b[39m[commit_message], dictionary\u001b[39m=\u001b[39mdict_msg, params\u001b[39m=\u001b[39mparams, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmsg\u001b[39m\u001b[39m'\u001b[39m)        \n",
      "\u001b[1;32m/home/aiotlab3/RISE/Manh/TanDatasets/cc2vec-preprocessing-data.ipynb Cell 15\u001b[0m in \u001b[0;36mhunks_to_code\u001b[0;34m(file_levels)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Baiotlab3/home/aiotlab3/RISE/Manh/TanDatasets/cc2vec-preprocessing-data.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=193'>194</a>\u001b[0m code \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Baiotlab3/home/aiotlab3/RISE/Manh/TanDatasets/cc2vec-preprocessing-data.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=194'>195</a>\u001b[0m \u001b[39mfor\u001b[39;00m file_level \u001b[39min\u001b[39;00m file_levels:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Baiotlab3/home/aiotlab3/RISE/Manh/TanDatasets/cc2vec-preprocessing-data.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=195'>196</a>\u001b[0m     \u001b[39mfor\u001b[39;00m hunk \u001b[39min\u001b[39;00m file_level[\u001b[39m'\u001b[39;49m\u001b[39mcode_changes\u001b[39;49m\u001b[39m'\u001b[39;49m]:\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Baiotlab3/home/aiotlab3/RISE/Manh/TanDatasets/cc2vec-preprocessing-data.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=196'>197</a>\u001b[0m         code\u001b[39m.\u001b[39mappend(hunk[\u001b[39m'\u001b[39m\u001b[39madded_code\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Baiotlab3/home/aiotlab3/RISE/Manh/TanDatasets/cc2vec-preprocessing-data.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=197'>198</a>\u001b[0m         code\u001b[39m.\u001b[39mappend(hunk[\u001b[39m'\u001b[39m\u001b[39mremoved_code\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# DeepJIT\n",
    "code = hunks_to_code(train_commits)\n",
    "\n",
    "dict_msg, dict_code = dictionary\n",
    "\n",
    "pad_msg = padding_data(data=[commit_message], dictionary=dict_msg, params=params, type='msg')        \n",
    "pad_code = padding_data(data=[code], dictionary=dict_code, params=params, type='code')\n",
    "\n",
    "# CC2Vec\n",
    "added_code, removed_code = cc2vec_clean_and_reformat_code(train_commits)\n",
    "pad_added_code = cc2vec_padding_commit_code(data=added_code, max_file=params['code_file'], max_line=params['code_line'], max_length=params['cc2vec_code_length'])\n",
    "pad_removed_code = cc2vec_padding_commit_code(data=removed_code, max_file=params['code_file'], max_line=params['code_line'], max_length=params['cc2vec_code_length'])\n",
    "pad_added_code = cc2vec_mapping_dict_code(pad_code=pad_added_code, dict_code=dict_code)\n",
    "pad_removed_code = cc2vec_mapping_dict_code(pad_code=pad_removed_code, dict_code=dict_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manh-simcom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
