{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What this file does ?\n",
    "\n",
    "- Create message/code dictionary\n",
    "- Preprocessing message and code\n",
    "- Delete duplicate files in commit\n",
    "\n",
    "## Directories\n",
    "- `data\\{project_name}`: Yet preprocessed data here\n",
    "- `data\\{project_name}\\clean`: Preprocessed data here\n",
    "- `{project_name}_(train/test)_(dextend).pkl`: commit data name\n",
    "- `{project_name}_feature_(train/test).pkl`: feature data name\n",
    "- `{project_name}_dict.pkl`: dictionary name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from Dict import Dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test set\n",
    "\n",
    "Set up:\n",
    "1. Change `data` and `test` path\n",
    "2. Change `project_name` (optional if specify in path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'moment'\n",
    "\n",
    "train = pickle.load(open(f'data/{project_name}/clean/{project_name}_train.pkl', 'rb'))\n",
    "test = pickle.load(open(f'data/{project_name}/clean/{project_name}_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[6]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create message dictionary and code dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_dict = Dict(lower=True)\n",
    "code_dict = Dict(lower=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentence(sentence):\n",
    "    sentence = sentence.replace('.', ' . ').replace('_', ' ').replace('@', ' @ ')\\\n",
    "        .replace('-', ' - ').replace('~', ' ~ ').replace('%', ' % ').replace('^', ' ^ ')\\\n",
    "        .replace('&', ' & ').replace('*', ' * ').replace('(', ' ( ').replace(')', ' ) ')\\\n",
    "        .replace('+', ' + ').replace('=', ' = ').replace('{', ' { ').replace('}', ' } ')\\\n",
    "        .replace('|', ' | ').replace('\\\\', ' \\ ').replace('[', ' [ ').replace(']', ' ] ')\\\n",
    "        .replace(':', ' : ').replace(';', ' ; ').replace(',', ' , ').replace('<', ' < ')\\\n",
    "        .replace('>', ' > ').replace('?', ' ? ').replace('/', ' / ')\n",
    "    sentence = ' '.join(sentence.split())\n",
    "    return sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out duplicate files in commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def filter_duplicate(my_list: list):\n",
    "    unique_dict = {}\n",
    "    for dictionary in my_list:\n",
    "        key = json.dumps(dictionary, sort_keys=True)\n",
    "        unique_dict[key] = dictionary\n",
    "\n",
    "    # Get the unique elements from the dictionary\n",
    "    unique_elements = list(unique_dict.values())\n",
    "\n",
    "    return unique_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for commit in train + test:\n",
    "    filterd_commit = filter_duplicate(commit['main_language_file_changes'])\n",
    "    commit['main_language_file_changes'] = filterd_commit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dictionaries and preprocessing code in train-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "messages = []\n",
    "cc2vec_commits = []\n",
    "deepjit_commits = []\n",
    "labels = []\n",
    "\n",
    "for commit in train:\n",
    "    message = commit['commit_message'].strip()\n",
    "    message = split_sentence(message)\n",
    "    message = ' '.join(message.split(' ')).lower()\n",
    "\n",
    "    for word in message.split():\n",
    "        msg_dict.add(word)\n",
    "\n",
    "    cc2vec_commit = []\n",
    "    deepjit_commit = []\n",
    "    for file in commit['main_language_file_changes']:\n",
    "        list_of_added_code = []\n",
    "        list_of_removed_code = []\n",
    "        for hunk in file['code_changes']:\n",
    "            added_code = hunk['added_code']\n",
    "            removed_code = hunk['removed_code']\n",
    "\n",
    "            added_code = added_code.strip()\n",
    "            removed_code = removed_code.strip()\n",
    "\n",
    "            added_code = ' '.join(split_sentence(added_code).split())\n",
    "            removed_code = ' '.join(split_sentence\n",
    "            (removed_code).split())\n",
    "\n",
    "            added_code = ' '.join(added_code.split(' '))\n",
    "            removed_code = ' '.join(removed_code.split(' '))\n",
    "\n",
    "            list_of_added_code.append(added_code)\n",
    "            list_of_removed_code.append(removed_code)\n",
    "            deepjit_commit.append(added_code)\n",
    "            deepjit_commit.append(removed_code)\n",
    "\n",
    "            for word in added_code.split():\n",
    "                code_dict.add(word)\n",
    "            for word in removed_code.split():\n",
    "                code_dict.add(word)\n",
    "        \n",
    "        cc2vec_commit.append({\n",
    "            'added_code': list_of_added_code,\n",
    "            'removed_code': list_of_removed_code\n",
    "        })\n",
    "\n",
    "    ids.append(commit['commit_hash'])\n",
    "    messages.append(message)\n",
    "    cc2vec_commits.append(cc2vec_commit)\n",
    "    deepjit_commits.append(deepjit_commit)\n",
    "    labels.append(commit['bug_inducing'])\n",
    "        \n",
    "msg_dict = msg_dict.prune(100000)\n",
    "code_dict = code_dict.prune(100000)\n",
    "project_dict = [msg_dict.get_dict(), code_dict.get_dict()]\n",
    "\n",
    "cc2vec_preprocessed_train = [ids, messages, cc2vec_commits, labels]\n",
    "deepjit_preprocessed_train = [ids, messages, deepjit_commits, labels]\n",
    "\n",
    "pickle.dump(project_dict, open(f\"data/{project_name}/clean/{project_name}_dict.pkl\", 'wb'))\n",
    "pickle.dump(cc2vec_preprocessed_train, open(f\"data/{project_name}/clean/{project_name}_train.pkl\", 'wb'))\n",
    "pickle.dump(deepjit_preprocessed_train, open(f\"data/{project_name}/clean/{project_name}_train_dextend.pkl\", 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing code in test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "messages = []\n",
    "cc2vec_commits = []\n",
    "deepjit_commits = []\n",
    "labels = []\n",
    "\n",
    "for commit in test:\n",
    "    message = commit['commit_message'].strip()\n",
    "    message = split_sentence(message)\n",
    "    message = ' '.join(message.split(' ')).lower()\n",
    "\n",
    "    cc2vec_commit = []\n",
    "    deepjit_commit = []\n",
    "    for file in commit['main_language_file_changes']:\n",
    "        list_of_added_code = []\n",
    "        list_of_removed_code = []\n",
    "        for hunk in file['code_changes']:    \n",
    "            added_code = hunk['added_code']\n",
    "            removed_code = hunk['removed_code']\n",
    "\n",
    "            added_code = added_code.strip()\n",
    "            removed_code = removed_code.strip()\n",
    "\n",
    "            added_code = ' '.join(split_sentence(added_code).split())\n",
    "            removed_code = ' '.join(split_sentence\n",
    "            (removed_code).split())\n",
    "\n",
    "            added_code = ' '.join(added_code.split(' '))\n",
    "            removed_code = ' '.join(removed_code.split(' '))\n",
    "\n",
    "            list_of_added_code.append(added_code)\n",
    "            list_of_removed_code.append(removed_code)\n",
    "            deepjit_commit.append(added_code)\n",
    "            deepjit_commit.append(removed_code)\n",
    "        \n",
    "        cc2vec_commit.append({\n",
    "            'added_code': list_of_added_code,\n",
    "            'removed_code': list_of_removed_code\n",
    "        })\n",
    "\n",
    "    ids.append(commit['commit_hash'])\n",
    "    messages.append(message)\n",
    "    cc2vec_commits.append(cc2vec_commit)\n",
    "    deepjit_commits.append(deepjit_commit)\n",
    "    labels.append(commit['bug_inducing'])\n",
    "\n",
    "cc2vec_preprocessed_test = [ids, messages, cc2vec_commits, labels]\n",
    "deepjit_preprocessed_test = [ids, messages, deepjit_commits, labels]\n",
    "\n",
    "pickle.dump(cc2vec_preprocessed_test, open(f\"data/{project_name}/clean/{project_name}_test.pkl\", 'wb'))\n",
    "pickle.dump(deepjit_preprocessed_test, open(f\"data/{project_name}/clean/{project_name}_test_dextend.pkl\", 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manh-simcom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
